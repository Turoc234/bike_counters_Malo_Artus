{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18cc7ae5-7438-402e-8196-bb931e3e6c6f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# RAMP on predicting cyclist traffic in Paris\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The dataset was collected with cyclist counters installed by Paris city council in multiple locations. It contains hourly information about cyclist traffic, as well as the following features,\n",
    " - counter name\n",
    " - counter site name\n",
    " - date\n",
    " - counter installation date\n",
    " - latitude and longitude\n",
    " \n",
    "Available features are quite scarce. However, **we can also use any external data that can help us to predict the target variable.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\artus\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from geopy.distance import geodesic\n",
    "import holidays\n",
    "from xgboost import XGBRegressor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Useful fonctions\n",
    "\n",
    "local_path = \"data/train.parquet\"\n",
    "kaggle_path = \"/kaggle/input/mdsb-2023/train.parquet\"\n",
    "_target_column_name = \"log_bike_count\"\n",
    "paris_center = (48.8566, 2.3522)\n",
    "\n",
    "\n",
    "def get_train_data(path=local_path):\n",
    "    data = pd.read_parquet(path)\n",
    "    # Sort by date first, so that time based cross-validation would produce correct results\n",
    "    data = data.sort_values([\"date\", \"counter_name\"])\n",
    "    y_array = data[_target_column_name].values\n",
    "    X_df = data.drop([_target_column_name, \"bike_count\"], axis=1)\n",
    "    return X_df, y_array\n",
    "\n",
    "\n",
    "def _encode_dates(X):\n",
    "    X = X.copy()  # modify a copy of X\n",
    "    # Encode the date information from the DateOfDeparture columns\n",
    "    X[\"year\"] = X[\"date\"].dt.year\n",
    "    X[\"month\"] = X[\"date\"].dt.month\n",
    "    X[\"day\"] = X[\"date\"].dt.day\n",
    "    X[\"weekday\"] = X[\"date\"].dt.weekday\n",
    "    X[\"hour\"] = X[\"date\"].dt.hour\n",
    "\n",
    "    return X.drop(columns=[\"date\"])\n",
    "\n",
    "\n",
    "def get_season(date):\n",
    "    mois = date.month\n",
    "    if 3 <= mois <= 5:\n",
    "        return 1  # Printemps\n",
    "    elif 6 <= mois <= 8:\n",
    "        return 2  # Été\n",
    "    elif 9 <= mois <= 11:\n",
    "        return 3  # Automne\n",
    "    else:\n",
    "        return 4  # Hiver\n",
    "\n",
    "\n",
    "def get_TimeOfDay(date):\n",
    "    heure = date.hour\n",
    "    if heure > 3 and heure <= 6:\n",
    "        return 1\n",
    "    if heure > 6 and heure <= 10:\n",
    "        return 2\n",
    "    elif heure > 10 and heure <= 13:\n",
    "        return 3\n",
    "    elif heure > 13 and heure <= 17:\n",
    "        return 4\n",
    "    elif heure > 17 and heure <= 22:\n",
    "        return 5\n",
    "    else:\n",
    "        return 6\n",
    "\n",
    "\n",
    "def assign_temperature(row):\n",
    "    hour = row[\"date\"].hour\n",
    "    if 6 <= hour <= 11:\n",
    "        return row[\"TEMPERATURE_MORNING_C\"]\n",
    "    elif 12 <= hour <= 17:\n",
    "        return row[\"TEMPERATURE_NOON_C\"]\n",
    "    elif 18 <= hour <= 23:\n",
    "        return row[\"TEMPERATURE_EVENING_C\"]\n",
    "    elif 0 <= hour <= 5:\n",
    "        return row[\"TEMPERATURE_NIGHT_C\"]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def classify_distance(row):\n",
    "    distance = geodesic((row[\"latitude\"], row[\"longitude\"]), paris_center).km\n",
    "\n",
    "    if distance < 2:  # Adjust this threshold based on your criteria\n",
    "        return 1  # Center\n",
    "    elif distance < 6:\n",
    "        return 2  # Intermediate\n",
    "    else:\n",
    "        return 3  # Peripheral\n",
    "\n",
    "\n",
    "def identity(x):\n",
    "    return x\n",
    "\n",
    "\n",
    "def is_holiday(date):\n",
    "    return 0 if date in holidays else 1\n",
    "\n",
    "\n",
    "# Getting the train and test data\n",
    "\n",
    "if Path(local_path).exists():\n",
    "    X_train, y_train = get_train_data()\n",
    "    X_test = pd.read_parquet(\"data/final_test.parquet\")\n",
    "    data_ext = pd.read_csv(Path(\"data\") / \"external_data.csv\")\n",
    "    weather_2021 = pd.read_csv(\"data/export-paris2021.csv\", sep=\",\")\n",
    "    weather_2020 = pd.read_csv(\"data/export-paris2020.csv\", sep=\",\")\n",
    "\n",
    "elif Path(kaggle_path).exists():\n",
    "    X_train, y_train = get_train_data(path=kaggle_path)\n",
    "    X_test = pd.read_parquet(\"/kaggle/input/mdsb-2023/final_test.parquet\")\n",
    "    data_ext = pd.read_csv(\"/kaggle/input/mdsb-2023/external_data.csv\")\n",
    "    weather_2021 = pd.read_csv(\"/kaggle/input/mto-2/export-paris2021.csv\", sep=\",\")\n",
    "    weather_2020 = pd.read_csv(\"/kaggle/input/mto-2/export-paris2020.csv\", sep=\",\")\n",
    "\n",
    "else:\n",
    "    print(\"error in path\")\n",
    "\n",
    "X_test = X_test.drop(\n",
    "    columns=[\n",
    "        \"site_id\",\n",
    "        \"counter_id\",\n",
    "        \"coordinates\",\n",
    "        \"counter_technical_id\",\n",
    "        \"counter_installation_date\",\n",
    "    ]\n",
    ")\n",
    "X_train = X_train.drop(\n",
    "    columns=[\n",
    "        \"site_id\",\n",
    "        \"counter_id\",\n",
    "        \"coordinates\",\n",
    "        \"counter_technical_id\",\n",
    "        \"counter_installation_date\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "# External data preprocessing\n",
    "\n",
    "weather = pd.concat([weather_2020, weather_2021], ignore_index=True)\n",
    "weather.rename(columns={\"DATE\": \"date_jour\"}, inplace=True)\n",
    "weather[\"date_jour\"] = pd.to_datetime(weather[\"date_jour\"])\n",
    "weather.drop(\n",
    "    columns=[\n",
    "        \"MAX_TEMPERATURE_C\",\n",
    "        \"MIN_TEMPERATURE_C\",\n",
    "        \"WINDSPEED_MAX_KMH\",\n",
    "        \"HUMIDITY_MAX_PERCENT\",\n",
    "        \"VISIBILITY_AVG_KM\",\n",
    "        \"PRESSURE_MAX_MB\",\n",
    "        \"CLOUDCOVER_AVG_PERCENT\",\n",
    "        \"HEATINDEX_MAX_C\",\n",
    "        \"DEWPOINT_MAX_C\",\n",
    "        \"WINDTEMP_MAX_C\",\n",
    "        \"WEATHER_CODE_MORNING\",\n",
    "        \"WEATHER_CODE_NOON\",\n",
    "        \"WEATHER_CODE_EVENING\",\n",
    "        \"TOTAL_SNOW_MM\",\n",
    "        \"UV_INDEX\",\n",
    "        \"SUNHOUR\",\n",
    "        \"OPINION\",\n",
    "        \"SUNSET\",\n",
    "        \"SUNRISE\",\n",
    "    ],\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "# Merging external data with train set\n",
    "\n",
    "X_train[\"date_jour\"] = X_train[\"date\"].dt.date\n",
    "X_train[\"date_jour\"] = pd.to_datetime(X_train[\"date_jour\"])\n",
    "X_train = X_train.merge(right=weather, on=\"date_jour\", how=\"left\")\n",
    "\n",
    "# Feature engineering on train set\n",
    "\n",
    "X_train[\"is_weekend\"] = X_train[\"date\"].apply(lambda x: 1 if x.weekday() >= 5 else 0)\n",
    "holidays = holidays.CountryHoliday(\"France\")\n",
    "X_train[\"is_holiday\"] = X_train[\"date\"].apply(is_holiday)\n",
    "X_train[\"season\"] = X_train[\"date\"].apply(get_season)\n",
    "X_train[\"timeOfDay\"] = X_train[\"date\"].apply(get_TimeOfDay)\n",
    "# X_train['is_couvre_feu'] = X_train.apply(encode_couvre_feu, axis=1)\n",
    "X_train[\"is_confinement\"] = (\n",
    "    (X_train[\"date\"] > \"2020-03-17\") & (X_train[\"date\"] < \"2020-05-11\")\n",
    "    | (X_train[\"date\"] > \"2020-10-30\") & (X_train[\"date\"] < \"2020-12-15\")\n",
    "    | (X_train[\"date\"] > \"2021-04-03\") & (X_train[\"date\"] < \"2021-05-03\")\n",
    ")\n",
    "# X_train['temperature'] = X_train.apply(assign_temperature, axis=1)\n",
    "X_train[\"distance_category\"] = X_train.apply(classify_distance, axis=1)\n",
    "X_train[\"is_raining\"] = X_train[\"PRECIP_TOTAL_DAY_MM\"].apply(\n",
    "    lambda x: 1 if x > 5 else 0\n",
    ")\n",
    "X_train = X_train.drop(\n",
    "    columns=[\n",
    "        \"TEMPERATURE_NIGHT_C\",\n",
    "        \"TEMPERATURE_MORNING_C\",\n",
    "        \"TEMPERATURE_NOON_C\",\n",
    "        \"TEMPERATURE_EVENING_C\",\n",
    "        \"PRECIP_TOTAL_DAY_MM\",\n",
    "        \"latitude\",\n",
    "        \"longitude\",\n",
    "        \"date_jour\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Feeling nAn values\n",
    "\n",
    "\n",
    "# Merging external data with test set\n",
    "\n",
    "X_test[\"date_jour\"] = X_test[\"date\"].dt.date\n",
    "X_test[\"date_jour\"] = pd.to_datetime(X_test[\"date_jour\"])\n",
    "X_test = X_test.merge(right=weather, on=\"date_jour\", how=\"left\")\n",
    "\n",
    "# Feature engineering on test set\n",
    "\n",
    "X_test[\"is_weekend\"] = X_test[\"date\"].apply(lambda x: 1 if x.weekday() >= 5 else 0)\n",
    "X_test[\"is_holiday\"] = X_test[\"date\"].apply(is_holiday)\n",
    "X_test[\"season\"] = X_test[\"date\"].apply(get_season)\n",
    "X_test[\"timeOfDay\"] = X_test[\"date\"].apply(get_TimeOfDay)\n",
    "X_test[\"is_confinement\"] = (\n",
    "    (X_test[\"date\"] > \"2020-03-17\") & (X_test[\"date\"] < \"2020-05-11\")\n",
    "    | (X_test[\"date\"] > \"2020-10-30\") & (X_test[\"date\"] < \"2020-12-15\")\n",
    "    | (X_test[\"date\"] > \"2021-04-03\") & (X_test[\"date\"] < \"2021-05-03\")\n",
    ")\n",
    "# X_test['is_couvre_feu'] = X_test.apply(encode_couvre_feu, axis=1)\n",
    "# X_test['temperature'] = X_test.apply(assign_temperature, axis=1)\n",
    "X_test[\"distance_category\"] = X_test.apply(classify_distance, axis=1)\n",
    "X_test[\"is_raining\"] = X_test[\"PRECIP_TOTAL_DAY_MM\"].apply(lambda x: 1 if x > 5 else 0)\n",
    "X_test = X_test.drop(\n",
    "    columns=[\n",
    "        \"TEMPERATURE_NIGHT_C\",\n",
    "        \"TEMPERATURE_MORNING_C\",\n",
    "        \"TEMPERATURE_NOON_C\",\n",
    "        \"TEMPERATURE_EVENING_C\",\n",
    "        \"PRECIP_TOTAL_DAY_MM\",\n",
    "        \"latitude\",\n",
    "        \"longitude\",\n",
    "        \"date_jour\",\n",
    "    ]\n",
    ")\n",
    "# Encoding the dataset\n",
    "\n",
    "date_encoder = FunctionTransformer(_encode_dates)\n",
    "date_cols = _encode_dates(X_train[[\"date\"]]).columns.tolist()\n",
    "\n",
    "categorical_encoder = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "categorical_cols = [\"counter_name\", \"site_name\", \"season\", \"timeOfDay\"]\n",
    "\n",
    "binary_cols = [\n",
    "    \"is_weekend\",\n",
    "    \"is_holiday\",\n",
    "    \"is_raining\",\n",
    "    \"is_confinement\",\n",
    "    \"distance_category\",\n",
    "]\n",
    "binary_encoder = FunctionTransformer(func=identity, validate=False)\n",
    "\n",
    "numerical_encoder = StandardScaler()\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\"date\", OneHotEncoder(handle_unknown=\"ignore\", sparse=False), date_cols),\n",
    "        (\"cat\", categorical_encoder, categorical_cols),\n",
    "        (\"bin\", binary_encoder, binary_cols),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Model selection\n",
    "\n",
    "regressor = XGBRegressor(learning_rate=0.1, max_depth=11, n_estimations=300)\n",
    "\n",
    "# Pipeline creation and fitting\n",
    "\n",
    "pipe = make_pipeline(date_encoder, preprocessor, regressor)\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Making the prediction\n",
    "\n",
    "y_pred = pipe.predict(X_test)\n",
    "y_pred[y_pred < 0] = 0\n",
    "results = pd.DataFrame(\n",
    "    dict(\n",
    "        Id=np.arange(y_pred.shape[0]),\n",
    "        log_bike_count=y_pred,\n",
    "    )\n",
    ")\n",
    "results.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
